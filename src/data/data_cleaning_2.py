import pandas as pd
import numpy as np
import unicodedata

df = pd.read_excel("../data/df_2022.xlsx")

df.columns

column_mapping = {
    "Tipo de documento de identidad": "Tipo_de_Documento",
    "Fecha de nacimiento:": "Fecha_de_Nacimiento",
    "Dirección de residencia en Bogotá:": "Direccion_de_Residencia_Bogota",
    "Para lugares diferentes a las opciones, mencionar Departamento y Municipio (Ejemplo, Córdoba/San Pelayo)": "Otra_Ubicacion",
    "Nivel de estudio": "Nivel_de_Estudio",
    "Tipo de admisión": "Tipo_de_Admision",
    "Programa curricular de pregrado al cual pertenece (Estudiantes de pregrado)": "Programa_de_Pregrado",
    "Papa": "PAPA",
    "Avance": "Progreso",
    "Número de matrícula:": "Numero_de_Matricula",
    "¿Cursa doble titulación?": "Matricula_Doble_Titulacion",
    "Carrera doble titulación": "Programa_Doble_Titulacion",
    "Porcentaje de avance segunda carrera": "Porcentaje_Progreso_Doble_Titulacion",
    "PBM:": "PBM",
    "Estrato": "Estrato_Socioeconomico",
    "¿Presento solicitud de Reubicación socioeconómica? ": "Solicitud_Reubicacion_Socioeconomica",
    "¿Fue aprobada su solicitud de reubicación socioeconómica? ": "Aprobacion_Solicitud_Reubicacion",
    "¿Cuenta con algún apoyo económico de la Universidad o de otra institución? ": "Apoyo_Economico",
    "¿Cuál? ": "Fuente_de_Apoyo",
    "Otras actividades que realice en este momento ": "Otras_Actividades_Actuales",
    "¿Ha estado vinculado con anterioridad a la Dirección de Bienestar de la Facultad de Ingeniería?": "Involucramiento_Anterior_Bienestar",
    "Tipo de vinculación que ha tenido": "Tipo_Involucramiento_Anterior",
    "Número de convocatorias a las cuales ha estado vinculado anteriormente a la Dirección de Bienestar Ingeniería\n": "Convocatorias_Anteriores_Bienestar",
    "Desea confirmar su postulación?": "Confirmacion_Postulacion",
    "Cantidad de créditos inscritos para este semestre": "Creditos_Inscritos_Semestre",
    "Seleccione las condiciones de vulnerabilidad que considera ud aplican para su situación actual": "Condiciones_Vulnerabilidad_Seleccionadas",
    "Si lo desea, explique voluntariamente su condición de vulnerabilidad socioeconómica /académica \n ": "Explicacion_Vulnerabilidad",
}

# Rename the columns in your DataFrame
df.rename(columns=column_mapping, inplace=True)

# Lista de variables que deseas mantener
variables_deseadas = [
    "Fecha_de_Nacimiento",
    "Nivel_de_Estudio",
    "Tipo_de_Admision",
    "Programa_de_Pregrado",
    "PAPA",
    "Progreso",
    "Numero_de_Matricula",
    "Matricula_Doble_Titulacion",
    "Programa_Doble_Titulacion",
    "Porcentaje_Progreso_Doble_Titulacion",
    "PBM",
    "Estrato_Socioeconomico",
    "Solicitud_Reubicacion_Socioeconomica",
    "Aprobacion_Solicitud_Reubicacion",
    "Apoyo_Economico",
    "Fuente_de_Apoyo",
    "Otras_Actividades_Actuales",
    "Involucramiento_Anterior_Bienestar",
    "Tipo_Involucramiento_Anterior",
    "Convocatorias_Anteriores_Bienestar",
    "Confirmacion_Postulacion",
    "Creditos_Inscritos_Semestre",
    "Condiciones_Vulnerabilidad_Seleccionadas",
    "Explicacion_Vulnerabilidad",
]

# Filtrar el DataFrame para mantener solo las columnas deseadas

df = df[variables_deseadas]


# Función para eliminar tildes
def eliminar_tildes(texto):
    return "".join(
        (
            c
            for c in unicodedata.normalize("NFD", texto)
            if unicodedata.category(c) != "Mn"
        )
    )


# Convertir columnas a minúsculas y eliminar tildes
df.columns = df.columns.str.lower().map(eliminar_tildes)

df.isna().sum()

# El progreso puede ser cero porque es el primer semestre
df["progreso"] = df["progreso"].fillna(0)


# convertimos si esta estudiando doble ingenieria 1 si es TRUE 0 si es falso
df["programa_doble_titulacion"] = df["programa_doble_titulacion"].apply(
    lambda x: 1 if "ingeniería" in str(x).lower() else 0
)

df["porcentaje_progreso_doble_titulacion"] = pd.to_numeric(
    df["porcentaje_progreso_doble_titulacion"], errors="coerce"
).fillna(0)


df.shape

df["fuente_de_apoyo"].unique()

# Convert all categories to lowercase and remove leading and trailing whitespace
df["fuente_de_apoyo"] = df["fuente_de_apoyo"].str.lower().str.strip()

# Now, apply the replacement operation
df["fuente_de_apoyo"] = df["fuente_de_apoyo"].replace(
    {
        "almuerzo": "alimentación",
        "generacion e": "generación e",
        "generacion_e": "generación e",
        "alimentario": "alimentación",
        "apoyo alimentario básico - almuerzo": "alimentación",
        "generación e excelencia": "generación e",
        "tramporte": "transporte",
        "básica total - almuerzo": "alimentación",
        "no": 0,
        "n,a": 0,
        "tengo exención del pago de matrícula por mi promedio": "promedio",
        "programa de alimentacion": "alimentación",
        "no aplica": 0,
        "apoyo básica alimentaria desayuno": "alimentación",
        "alimentación (almuerzo)": "alimentación",
        "ninguna": 0,
        "apoyo transporte": "transporte",
        "jóvenes en acción": "jovenes en acción",
        "apoyo alimentario y jovenes en acción": "alimentación y jóvenes en acción",
        "un credito de sostenimiento, el cual no me alcanza,": "crédito sostenimiento",
        "promotor de convivencia": "promotor de convivencia",
        "promotores de convivencia 2022-01(finalizando último cumplido)": "promotor de convivencia",
        "apoyo alimentario y de transporte,": "alimentación y transporte",
        "apoyo de transporte": "transporte",
        "apoyo alimentario de almuerzo": "alimentación",
        "becario": "becario",
        "almuerzo, transporte": "almuerzo y transporte",
        "spp3": "ser pilo paga",
        "apoyo alimentario": "alimentación",
        "crédito sostenimiento icetex": "crédito sostenimiento",
        "almuerzo y transporte": "almuerzo y transporte",
        "almuerzo basico": "alimentación",
        "desayuno": "alimentación",
        "almuerzo en la universidad": "alimentación",
        "apoyo de alimentación y transporte": "alimentación y transporte",
        "descuento mejores promedios": "promedio",
        "almuerzo total": "alimentación",
        "ninguno": 0,
        "alojamiento": "alojamiento",
        "desayunos": "alimentación",
        "transporte y almuerzo": "alimentación y transporte",
        "bono alimentario": "alimentación",
        "alimentación-almuerzo": "alimentación",
        "cena": "alimentación",
        "alimentario y gen e": "alimentación y generacion e",
        "jovenes en acción": "jóvenes en acción",
        "alimentación y jóvenes en acción": "alimentación y jóvenes en acción",
        "promotor de convivencia": "promotor",
        "promotores": "promotor",
        "apoyo desayuno": "alimentación",
        "desayuno y transporte": "alimentación y transporte",
        "bono de alimento": "alimentación",
        "becario": "becario",
        "ser_pilo_paga": "ser pilo paga",
        "equidad": "equidad",
        "programa promotores": "promotor",
        "alimentario - desayuno": "alimentación",
        "apoyo a tutorias": 0,
        "ser pilo paga 4": "ser pilo paga",
        "promotores de convivencia 2022 1": "promotor",
        "vinculación a promotor de convivencia": "promotor",
        "alojamiento, y alimentación": "alimentacion y alojamiento",
        "matricula cero": 0,
    }
)

df["fuente_de_apoyo"].unique()


df["fuente_de_apoyo"].fillna(0, inplace=True)

df["fuente_de_apoyo"] = df["fuente_de_apoyo"].apply(
    lambda x: "ninguno" if x == 0 else x
)


df["otras_actividades_actuales"].unique()


df["otras_actividades_actuales"] = df["otras_actividades_actuales"].replace(
    {
        "NINGUNA": "No trabajo",
        "Ninguna": "No trabajo",
        "Participo del grupo institucional de tango": "deporte",
        "Ninguna de momento ": "No trabajo",
        "Semillero de investigación": "investigacion",
        "estudiar": "No trabajo",
        "Trabajo informal": "Trabajo",
        "Ayuda social": "No trabajo",
        "Actualmente ando en proceso de vincularme a un semillero de investigación (SIGREH) y me me desempeño como auxiliar de espacios en las tutorías con ingenio": "investigacion",
        "ESTUDIAR": "No trabajo",
        "No": "No trabajo",
        "Sólo estudiar": "No trabajo",
        "Horas de corresponsabilidad ": "No trabajo",
        "Curso de 45 horas del sena los viernes de 8 a 12": "No trabajo",
        "Hago parte del semillero de investigación Quantum Computing y Crea-lo": "investigacion",
        "Ninguna, y necesito trabajo para mis gastos :(": "No trabajo",
        "Voy a la iglesia": "No trabajo",
        "Tomo clases de baile (Salsa) en los talleres libres de la Universidad, actividad física desde casa, asistencia a Lunes de organización en la Universidad ": "deporte",
        "selección futbol sala fem": "deporte",
        "Taller de dibujo": "No trabajo",
        "EUN": "No trabajo",
        "Ninguna ": "No trabajo",
        "Trabajo para mantenerme y mantener a mi hija,": "Trabajo",
        "Dar tutorías personalizadas": "Trabajo",
        "Trabajar en lo que salga": "Trabajo",
        "Uno que otro trabajo por ahí, para cubrir los gastos,": "Trabajo",
        "Realizar y vender algunas artesanías ": "Trabajo",
        "ninguna": "No trabajo",
        "Trabajar los fines de semana": "Trabajo",
        "Estudiar y trabajar en chazas": "Trabajo",
        "Práctico Futbol en la Universidad Nacional ": "deporte",
        "Participo en el grupo de investigación con el cual realicé mi práctica universitaria el semestre pasado,": "investigacion",
        "Semillero de Investigación - SIHU": "investigacion",
        "Trabajar ": "Trabajo",
        "Selección de ajedrez ": "deporte",
        " ": "No trabajo",
        "solo estudio ": "No trabajo",
        "Trabajo en tiempos libres,": "Trabajo",
        "Trabajo en el centro": "Trabajo",
        "solo estudiar": "No trabajo",
        "Particiapacion en grupo Inovate": "investigacion",
        "Integrante del Grupo de Salsa de la Universidad Nacional": "deporte",
        "Estudiar, e ir al gimnasio y transportarme en Bogotá que es un martirio ": "No trabajo",
        "Ejercicio, hora media al día ": "deporte",
        "Hago parte de dos grupos de investigación de la facultad": "investigacion",
        "no": "No trabajo",
        "Buscando un trabajo fijo porque no tengo ingresos fijos como tal,": "Trabajo",
        "aclaro el monto del becariato : 191000/mes": "No trabajo",
        "DEPORTE": "deporte",
        "Solo estudio,": "No trabajo",
        "Estudiante auxiliar división de extensión": "No trabajo",
        "Curso virtuales MinTic, trabajos ocasionales, entrenamiento deportivo equipo de softbol UNAL": "investigacion",
        "Entrenamiento": "deporte",
        "Estudiar": "No trabajo",
        "Trabajo algunos fines de semana ": "Trabajo",
        "Estudio y busco trabajo para mi manutención ": "Trabajo",
        "Participación en orquesta Sonora latina de la UNAL": "deporte",
        "Practicar joropo y andar en bicicleta los fines de semana": "deporte",
        "Ninguna, solo estudiar": "No trabajo",
        "Estudiante y vinculado al programa promotores": "No trabajo",
        "Estudiante auxiliar en un grupo de investigación": "investigacion",
        "tengo un emprendimiento de venta de ropa": "Trabajo",
        "Trabajar en confección": "Trabajo",
        "Programa ONE y grupo de programacion competitiva de la un": "investigacion",
        "semilleros de investigación": "investigacion",
        "En este momento solo me encuentro estudiando": "No trabajo",
        "Trabajo": "Trabajo",
        "Jugador de la selección masculina de baloncesto de la universidad, director de finanzas de ANEIAP del capítulo de la universidad sede Bogotá,": "deporte",
        "Tesis": "investigacion",
        "Curso amcharm de 2 a 6 todos los días": "No trabajo",
        "NO": "No trabajo",
        "No ": "No trabajo",
        np.nan: "No trabajo",
    }
)


df["otras_actividades_actuales"].fillna(0, inplace=True)


df["tipo_involucramiento_anterior"] = df["tipo_involucramiento_anterior"].fillna(
    "Ninguna"
)

df["convocatorias_anteriores_bienestar"].unique()

df["convocatorias_anteriores_bienestar"] = df[
    "convocatorias_anteriores_bienestar"
].replace(
    {
        "NINGUNA": 0,
        float("nan"): 0,
        "ninguna": 0,
        "No he estado vinculado a ninguna convocatoria de la facultad; sin embargo he sido participe del programa de practica colombia": 1,
        "Ninguna": 0,
        "No aplica": 0,
        "Ninguna ": 0,
        "N,A": 0,
        "2021-1 y 2022-1": 2,
        "UNA": 1,
    }
)


import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans

# Descargar los recursos necesarios de NLTK
nltk.download("omw-1.4")
nltk.download("punkt")
nltk.download("stopwords")
nltk.download("wordnet")

descriptions = df["explicacion_vulnerabilidad"]
# Preprocesamiento de las descripciones

# Preprocesamiento de las descripciones
stop_words = set(stopwords.words("spanish"))
lemmatizer = WordNetLemmatizer()

preprocessed_descriptions = []
valid_indices = []  # Almacena los índices válidos

for i, description in enumerate(df["explicacion_vulnerabilidad"]):
    # Verificar si el elemento es de tipo str
    if isinstance(description, str):
        # Tokenización de las palabras
        tokens = word_tokenize(description.lower())

        # Eliminación de las palabras de parada (stop words)
        tokens = [token for token in tokens if token not in stop_words]

        # Lematización de las palabras
        tokens = [lemmatizer.lemmatize(token) for token in tokens]

        preprocessed_descriptions.append(" ".join(tokens))
        valid_indices.append(i)  # Registrar el índice válido

# Extracción de características con TF-IDF
vectorizer = TfidfVectorizer()
feature_matrix = vectorizer.fit_transform(preprocessed_descriptions)

# Agrupamiento de las descripciones con K-means
num_clusters = 4
kmeans = KMeans(n_clusters=num_clusters, random_state=17)
kmeans.fit(feature_matrix)

# Asignar cada descripción a una categoría
categories = kmeans.predict(feature_matrix)

# Agregar la columna de categoría al DataFrame
df.loc[valid_indices, "categoria"] = categories

# Llenar los valores faltantes con cero

df["categoria"].fillna(0, inplace=True)


# Los datos representan categorias y no numeros float, estamos trabajando con una variable cualitativa
df["categoria"] = df["categoria"].apply(lambda x: str(x))


# Despues de encontrar las categorias podemos eliminar la columna
del df["explicacion_vulnerabilidad"]

df["condiciones_vulnerabilidad_seleccionadas"].unique()

del df["condiciones_vulnerabilidad_seleccionadas"]
df.info()

df.isna().sum()

df.to_csv("../data/data_clean_2.csv", index=False)
